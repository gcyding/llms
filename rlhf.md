# 强化学习相关
## RW

### 系列1
[OpenRLHF源码解读：理解Reward Model训练过程](https://zhuanlan.zhihu.com/p/14993645091)

[聊聊PRM（过程奖励模型）](https://zhuanlan.zhihu.com/p/15540962086)

[OpenRLHF源码解读：理解PRM(过程奖励模型)训练过程](https://zhuanlan.zhihu.com/p/16027048017)

### 系列2
[RLHF】想训练ChatGPT？先来看看强化学习（RL）+语言模型（LM）吧（附源码）](https://zhuanlan.zhihu.com/p/606328992)

[【RLHF】想训练ChatGPT？得先弄明白Reward Model怎么训（附源码）](https://zhuanlan.zhihu.com/p/595579042)

## PPO

### 相关论文
[Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347)
### 系列1
[OpenRLHF源码解读：1.理解PPO单机训练](https://zhuanlan.zhihu.com/p/13043187674)

[OpenRLHF源码解读：2.PPO训练Experience数据采样过程](https://zhuanlan.zhihu.com/p/14569025663)

[OpenRLHF源码解读：3.PPO模型训练过程](https://zhuanlan.zhihu.com/p/14813158239)

### 系列2
[图解大模型RLHF系列之：人人都能看懂的PPO原理与源码解读](https://zhuanlan.zhihu.com/p/677607581)
[RLHF通俗理解](https://zhuanlan.zhihu.com/p/685261886)

## 综合
### 系列1
[大模型是这样炼成的](https://mp.weixin.qq.com/s/D6gtKpNm9PP-NCm2PdUFlg)

[大模型中的强化学习——大语言模型研究05](https://limoncc.com/post/c0a3be9c86b2b4cd/)

[一文搞懂大模型强化学习策略：DPO、PPO和GRPO](https://mp.weixin.qq.com/s/JKpkgGHqyAVG95sGC1JFDQ)
